{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ea9b60",
   "metadata": {},
   "source": [
    "# **Chapter 7: Synchronization Examples – Exercise Solutions**\n",
    "\n",
    "## **Exercise 7.12**\n",
    "**Question:**  \n",
    "Describe two kernel data structures in which race conditions are possible. Be sure to include a description of how a race condition can occur.\n",
    "\n",
    "**Answer:**  \n",
    "1. **Process/Thread Control Block (PCB/TCB) Linked List**  \n",
    "   - **Race Condition**: When a new process is created or terminated, the kernel must update the linked list of PCBs. If two CPUs simultaneously attempt to insert or remove a PCB (e.g., during `fork()` and `exit()`), they may both manipulate the `next` pointers concurrently, corrupting the list. For example, both might read the same head pointer, then update it to point to their own new PCB, causing one insertion to be lost or creating a loop.\n",
    "\n",
    "2. **Memory Allocation Buddy System Free List**  \n",
    "   - **Race Condition**: The buddy system maintains lists of free memory blocks of different sizes. When allocating or freeing a block, the kernel must remove or insert blocks from these lists. If two processes on different cores simultaneously request memory of the same size, they might both find the same free block in the list, both attempt to remove it, and both believe they have acquired it, leading to double allocation and potential memory corruption.\n",
    "\n",
    "---\n",
    "\n",
    "## **Exercise 7.13**\n",
    "**Question:**  \n",
    "The Linux kernel has a policy that a process cannot hold a spinlock while attempting to acquire a semaphore. Explain why this policy is in place.\n",
    "\n",
    "**Answer:**  \n",
    "This policy prevents **deadlock** and **priority inversion** scenarios.  \n",
    "- A spinlock is designed for **short-term** locking in contexts where sleeping is not allowed (e.g., interrupt handlers). Holding a spinlock and then trying to acquire a semaphore (which may **block/sleep** if unavailable) would cause the thread to sleep while holding the spinlock.  \n",
    "- If the thread sleeps, another thread on the same CPU might try to acquire the same spinlock, causing **deadlock** because the lock is held by a sleeping thread.  \n",
    "- Additionally, spinning with a held semaphore could waste CPU indefinitely if the semaphore is held by a low-priority process that gets preempted.  \n",
    "The policy enforces that spinlocks are only used in non-blocking contexts.\n",
    "\n",
    "---\n",
    "\n",
    "## **Exercise 7.14**\n",
    "**Question:**  \n",
    "Design an algorithm for a bounded-buffer monitor in which the buffers (portions) are embedded within the monitor itself.\n",
    "\n",
    "**Answer:**  \n",
    "Monitor with internal buffer array and condition variables for empty/full.\n",
    "\n",
    "```java\n",
    "monitor BoundedBuffer {\n",
    "    private int buffer[N];\n",
    "    private int count = 0, in = 0, out = 0;\n",
    "    condition notFull, notEmpty;\n",
    "\n",
    "    void produce(int item) {\n",
    "        while (count == N) {\n",
    "            notFull.wait();  // wait until buffer not full\n",
    "        }\n",
    "        buffer[in] = item;\n",
    "        in = (in + 1) % N;\n",
    "        count++;\n",
    "        notEmpty.signal();  // signal consumer\n",
    "    }\n",
    "\n",
    "    int consume() {\n",
    "        while (count == 0) {\n",
    "            notEmpty.wait(); // wait until buffer not empty\n",
    "        }\n",
    "        int item = buffer[out];\n",
    "        out = (out + 1) % N;\n",
    "        count--;\n",
    "        notFull.signal();   // signal producer\n",
    "        return item;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Exercise 7.15**\n",
    "**Question:**  \n",
    "The strict mutual exclusion within a monitor makes the bounded-buffer monitor of Exercise 7.14 mainly suitable for small portions.\n",
    "a. Explain why this is true.\n",
    "b. Design a new scheme that is suitable for larger portions.\n",
    "\n",
    "**Answer:**  \n",
    "**a.** Strict mutual exclusion means only one thread can be active inside the monitor at a time. If the buffer operations (`produce`/`consume`) involve **large data portions** (e.g., copying large chunks of memory), the critical section becomes long. This serializes all producers and consumers, hurting **throughput** and **parallelism** unnecessarily, since multiple producers could fill different buffer slots concurrently, and multiple consumers could take from different slots concurrently.\n",
    "\n",
    "**b.** **Scheme for larger portions**: Use a **reader-writer** style approach or **fine-grained locking**.\n",
    "- Split the buffer into **multiple slots**, each with its own lock (or use an array of semaphores).\n",
    "- Producers and consumers can operate on **different slots simultaneously**.\n",
    "- Maintain shared counters (`count`, `in`, `out`) with atomic operations or a separate lock.\n",
    "\n",
    "**Pseudocode using multiple semaphores:**\n",
    "```c\n",
    "semaphore mutex = 1;          // protects in/out/count\n",
    "semaphore empty = N;          // counts empty slots\n",
    "semaphore full = 0;           // counts full slots\n",
    "semaphore slot_locks[N] = {1,1,...}; // one per slot\n",
    "\n",
    "void produce(int item, int slot_index) {\n",
    "    wait(empty);              // ensure space\n",
    "    wait(mutex);\n",
    "    // find free slot (could be predefined), e.g., slot_index = in;\n",
    "    wait(slot_locks[slot_index]); // lock this slot only\n",
    "    buffer[slot_index] = item; // copy large data\n",
    "    update in, count;\n",
    "    signal(mutex);\n",
    "    signal(slot_locks[slot_index]);\n",
    "    signal(full);\n",
    "}\n",
    "\n",
    "int consume(int slot_index) {\n",
    "    wait(full);\n",
    "    wait(mutex);\n",
    "    // find full slot, e.g., slot_index = out;\n",
    "    wait(slot_locks[slot_index]);\n",
    "    int item = buffer[slot_index];\n",
    "    update out, count;\n",
    "    signal(mutex);\n",
    "    signal(slot_locks[slot_index]);\n",
    "    signal(empty);\n",
    "    return item;\n",
    "}\n",
    "```\n",
    "This allows concurrent data copying into different buffer slots.\n",
    "\n",
    "---\n",
    "\n",
    "## **Exercise 7.16**\n",
    "**Question:**  \n",
    "Discuss the tradeoff between fairness and throughput of operations in the readers–writers problem. Propose a method for solving the readers–writers problem without causing starvation.\n",
    "\n",
    "**Answer:**  \n",
    "**Tradeoff**:  \n",
    "- **Throughput favor (Reader priority)**: Allows multiple readers simultaneously, maximizing read throughput, but **writers may starve** if readers keep arriving.  \n",
    "- **Fairness (Writer priority or FIFO)**: Writers get timely access, preventing starvation, but may reduce read throughput because readers are serialized or forced to wait.  \n",
    "\n",
    "**Starvation-Free Solution**:  \n",
    "Use a **fair scheduling policy** like:\n",
    "1. **Timestamp ordering**: Arriving threads (readers/writers) get a timestamp. Service in order; a writer blocks all later arrivals; a reader allows other readers with earlier timestamps to join.\n",
    "2. **The \"No Starvation\" Readers-Writers Lock**:  \n",
    "   - Use two mutexes: `resource_mutex` (for writers) and `read_count_mutex` (for reader count).  \n",
    "   - Add a **turnstile** semaphore or a **queue semaphore** to enforce FIFO order for both readers and writers.  \n",
    "   - When a writer is waiting, new readers are blocked until the writer finishes.  \n",
    "   - Implementation often uses a **fair semaphore** (like `pthread_rwlock` with priority to writers) or **condition variables with a queue**.\n",
    "\n",
    "**Example using condition variables:**\n",
    "```java\n",
    "monitor FairRW {\n",
    "    int readers = 0;\n",
    "    bool writing = false;\n",
    "    int waitingWriters = 0;\n",
    "    condition okToRead, okToWrite;\n",
    "\n",
    "    void startRead() {\n",
    "        while (writing || waitingWriters > 0) {\n",
    "            okToRead.wait();\n",
    "        }\n",
    "        readers++;\n",
    "        okToRead.signal(); // cascade to other waiting readers\n",
    "    }\n",
    "\n",
    "    void endRead() {\n",
    "        readers--;\n",
    "        if (readers == 0) {\n",
    "            okToWrite.signal();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    void startWrite() {\n",
    "        waitingWriters++;\n",
    "        while (readers > 0 || writing) {\n",
    "            okToWrite.wait();\n",
    "        }\n",
    "        waitingWriters--;\n",
    "        writing = true;\n",
    "    }\n",
    "\n",
    "    void endWrite() {\n",
    "        writing = false;\n",
    "        if (waitingWriters > 0) {\n",
    "            okToWrite.signal();\n",
    "        } else {\n",
    "            okToRead.signal();\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "This gives writers priority but ensures readers eventually proceed.\n",
    "\n",
    "---\n",
    "\n",
    "## **Exercise 7.17**\n",
    "**Question:**  \n",
    "Explain why the call to the `lock()` method in a Java `ReentrantLock` is not placed in the `try` clause for exception handling, yet the call to the `unlock()` method is placed in a `finally` clause.\n",
    "\n",
    "**Answer:**  \n",
    "- `lock()` is not placed in `try` because if `lock()` throws an exception (e.g., `InterruptedException`), the lock has **not been acquired**, so we should **not** attempt to unlock it in `finally`. Unlocking without ownership would cause an `IllegalMonitorStateException`.  \n",
    "- `unlock()` is placed in `finally` to **guarantee** that the lock is released if it was successfully acquired, even if an exception occurs in the critical section. This prevents deadlock.\n",
    "\n",
    "**Typical pattern:**\n",
    "```java\n",
    "ReentrantLock lock = new ReentrantLock();\n",
    "lock.lock();  // outside try\n",
    "try {\n",
    "    // critical section\n",
    "} finally {\n",
    "    lock.unlock(); // always unlock if locked\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Exercise 7.18**\n",
    "**Question:**  \n",
    "Explain the difference between software and hardware transactional memory.\n",
    "\n",
    "**Answer:**  \n",
    "- **Software Transactional Memory (STM)**: Implemented entirely in software (libraries, compiler support). It uses **logging**, **versioning**, or **copy-on-write** to group memory operations into atomic transactions. Conflicts are detected via software algorithms (e.g., using locks or timestamps). Higher overhead but portable across hardware.\n",
    "\n",
    "- **Hardware Transactional Memory (HTM)**: Supported directly by CPU hardware (e.g., Intel TSX, IBM POWER). Uses **cache coherence protocols** to detect conflicts and CPU caches to buffer speculative writes. Transactions are executed speculatively; if a conflict occurs (another core accesses same memory), hardware aborts and rolls back. Lower overhead, faster for small transactions, but limited by hardware constraints (cache size, instruction support).\n",
    "\n",
    "**Key difference**: HTM is faster and transparent to programmer but limited in transaction size and not universally available. STM is more flexible (larger transactions) but slower due to software overhead.\n",
    "\n",
    "--- \n",
    "\n",
    "**End of Chapter 7 Exercises**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
